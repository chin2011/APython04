	#中文显示
plt.rcParams['font.sans-serif'] = ['SimHei']
# 解决负号 '-' 显示为方块的问题
plt.rcParams['axes.unicode_minus'] = False


==============聚类Kmeans算法============
聚类算法简介

聚类算法API的使用
Kmeans实现流程
模型评估方法
案例顾客数据聚类分析法

-------------
聚类算法:
	·根据样本之间的 相似性，将样本划分到不同的类别中；不同的 相似度计算方法，会得到不同的聚类结果，常用的相似度计算方法有---欧式距离法。
	聚类算法的目的是在 没有先验知识 的情况下，自动发现数据集中的内在结构和模式。
	·无监督学习算法
	
使用不同的聚类准则，产生的聚类结果不同


1.根据聚类颗粒度分类
	细聚类 	组多  	簇: K=4
	粗聚类	组少	簇: K=2
	
2.根据实现方法分类
	K-means：按照质心分类，主要介绍K-means，通用、普遍
	层次聚类：对数据进行逐层划分，直到达到聚类的类别个数
	DBSCAN聚类	是一种基于密度的聚类算法
	谱聚类	是一种基于图论的聚类算法

---------------------------聚类算法API的使用----------------------

	estimator.fit_predict(x)
计算聚类中心并预测每个样本属于哪个类别，相当于先调用fit（x)，然后再调用predict（x）

	使用KMeans模型数据探索聚类

Kmeans简介：
	它属于无监督学习，即：有特征，无标签，根据样本间的相似性进行划分.
	所谓的相似性可以理解为就是距离，例如：欧式距离，曼哈顿（城市街区）距离，切比雪夫距离，闵式距离.··


------------------------KMeans算法实现流程---------------------------
1、事先确定常数K (几个簇)，常数K意味着最终的聚类类别数

2、随机选择 K 个样本点作为初始聚类中心

3、计算每个样本到K个中心的距离，选择最近的聚类中心点作为标记类别

4、根据每个类别中的样本点，重新计算出新的聚类中心点（平均值），如果计算得出的新中心点与上一次的中心点一样，则停止聚类，否则重新进行第3步过程，直到聚类中心不再变化

5、当每次迭代结果不变时，认为算法收敛，聚类完成


新中心点的计算:		(x , y)
	同一簇的: 	所有点的X 的平均--->x
				所有点的Y 的平均--->y

----------------------------------------------------

1. 了解 SSE 聚类评估指标
	误差平方和 SSE（The sum of squares due to error）1
	SSE越小，表示数据点越接近它们的中心，聚类效果越好
	
	(真实值 - 簇质心)² = 簇内距离~~误差 ²	(所有点--->各个质心)
	
	→开发流程：高内聚，低耦合，能自己搞定的事儿，就不要麻烦别人，


---------“肘”方法（Elbow method）－K值确定-------------
"肘”方法通过 SSE 确定 n_clusters 的值
	对于n个点的数据集，迭代计算k from 1to n，每次聚类完成后计算SSE
	SSE是会逐渐变小的，因为每个点都是它所在的簇中心本身。
	SSE变化过程中会出现一个拐点，下降率突然变缓时即认为是最佳nclusters值。
	在决定什么时候停止训练时，肘形判据同样有效，数据通常有更多的噪音，在增加分类无法带来更多回报时，我们停止增加类别。


思路1：SSE+肘部法
	SSE:
		概述：
			所有簇的所有样本到该簇质心的误差的平方和.
		特点：
			随着K值的增加，SSE值会逐渐减少
		目标：
			SSE值越小，代表簇内样本越聚集，内聚程度越高.
	肘部法：
		K值增大，SSE值会随之减小，下降梯度陡然变缓的得时候，那个K值，就是我们要的最佳值。

	中文:
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False








