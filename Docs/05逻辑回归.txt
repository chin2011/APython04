

==============逻辑回归=================
逻辑回归简介
	应用场景，数学知识
	逻辑回归=有监督学习，有特征，有标签，且标签是离散的（分类）
			=适用于 二分类

逻辑回归原理
	原理：数据，经过 线性回归->预测值->Sigmoid激活函数->映射到--概率 [0,1]
		(结合)基于你写的阔值->决定是A还是B (划分正 负样本)
			>0.6: A .........否则: B


逻辑回归API函数和案例

分类问题评估
	1.	混淆矩阵、(True：真	False：假	Positive:正例	Negative:反例)
							预测值（正例） 	预测值（反例）
	真实值（正例）			真正例（TP）	伪反例（FN)
	真实值（假例，反例）	伪正例（FP）	真反例（TN）

	2.	精确率、tp/(tp + fp)
		
	3.	召回率、tp/(tp+fn)
		
	4.	F1-score、AUC指标、ROC曲线
			
电信客户流失预测案例
 
------------------逻辑回归数学基础－sigmoid函数----------------------
激活函数== S型函数==sigmoid函数
	f(x)=1 / (1 +e ⁻ˣ	)
		作用: 把(-∞0,+∞0）映射到(0，1)

数学性质
	单调递增函数	拐点在x=0, y=0.5的位置
	
导函数公式	f′(x) =f(x) (1 -f(x))

------------------逻辑回归数学基础  概率------------------
概率－事件发生的可能性
	联合概率 和 条件概率是概率论中的基本概念，它们用于描述随机变量之间的关系
	北京早上堵车的可能性Pa=0.74 午堵车的可能性Pb=0.3 晚上堵车的可能性Pc=0.4
联合概率－指两个或多个随机变量同时发生的概率
	Pa=0.7 周1早上 周2早上同时堵车的概率PaPb=P(a|b)=0.7*0.7=0.49
条件概率－表示事件A在--另外一个事件B已经发生条件下的发生概率，P(a|b)
	Pa=0.7 周1早上堵车的情况下，中午再堵车的概率P(aIb)=0.7*0.3=0.21

P(a|b): b先发生  ,然后a发生

------------------极大似然估计 ------------------
核心思想：根据观测到的结果来估计模型算法中的未知参数

举个栗子
	假设有一枚不均匀的硬币，出现正面的概率和反面的概率是不同的。假定出现正面的概率为θ，
	抛了6次得到如下现象D={正面，反面，反面，正面，正面，正面}。每次投掷事件都是相互独立的。则根据产生的现象D，来估计参数θ是多少？
		正面:θ	反面:（1-θ）
	P(DIθ）=P{正面，反面，反面，正面，正面，正面}
		=P(正面|θ )P(反面|θ ) P(反面|θ )P(正面|θ ) P(正面|θ ）P(正面|θ）
		=θ *(1-θ )*(1-θ )θ *θ *θ = θ⁴ (1 - θ)²
		
	-->问题转化为：求此函数的极大值时，估计θ为多少！
	-->令导数f'(θ)=0,求极值，可估计出θ值 ₁ ₂ ₃
		--->θ₁ = 0, θ₂ = 1, θ₃ = 2/3
		--->θ = 2/3

------------------对数函数------------------
	如果aᵇ= N（a >0，b !=1)，那么b叫做以a为底N的对数。记为 b= loga N

从对数运算性质来看：能把几个概率 联乘的式子，改成log 相加的形式
	log a MN = log a M + log a N

------------------逻辑回归原理------------------
逻辑回归概念Logistic Regression
	一种分类模型，把线性回归的输出，作为逻辑回归的输入。
	--->输出是（0,1）之间的值

逻辑回归的假设函数
	h(w) = sigmoid(w ᵗ x + b )
		线性回归的输出，作为逻辑回归的输入

------------------逻辑回归原理－损失函数------------------
工作原理：
	每个样本预测值有A、B两个类别，真实类别对应的位置，概率值越大越好

1、一个样本的概率表示
	假设：有0、1两个类别，某个样本被分为1类的概率为 p,  则分为0类的概率为1-p，
	L =	 p		← ify=1
		1-p		← ify = 0

我们对损失函数的希望是：当样本是1类别，模型预测的p越大越好；
						当样本是0类别，模型预测的（1-p）越大越好；

2. n个样本的概率表示
	P=P(y₁|x₁)P(y₂ |x₂ )...P(yₙ|xₙ)

	1.Pᵢ 表示每个样本被分类正确时的概率
	2.yᵢ 表示每个样本的真实类别（0或1）

	问题转化为：让联合概率事件最大时，估计w、b的权重参数，这就是极大似然估计

3、极大似然函数转对数似然函数，取log优化函数：连乘形式转换为对数加法形式
		H(L)=....
	Loss(L) = -	H(L)	<---------最大化问题将其变为最小化问题
		逻辑回归的  损失函数 =－极大似然估计函数
	
4、使用梯度下降优化算法，更新逻辑回归算法的权重参数。

------------------逻辑回归API函数和案例------------------
数据描述
	（1）699条样本，共11列数据，第一列用语检索的id，后9列分别是与肿瘤相关的医学特征，
			最后一列表示肿瘤类型的数值。
	（2）包含16个缺失值，用”？”标出。
	（3）2表示良性，4表示恶性

	# 导包
	1.获取数据
	2.基本数据处理
	2.1 缺失值处理
	2.2确定特征值，目标值
	2.3分割数据
	3.特征工程(标准化）
	4.机器学习（逻辑回归）
	5.模型评估

#3.1特征提取之提取特征和标签。
	#按照行号，列索引获取数据，：表示所有行  1：-1表示从第1列到最后1列，包左不包右
x=data.iloc[ ：, 1:-1]

	#获取最后一列  三种方法:
data.iloc[:,-1]
y= data['Class']
y=data.Class

思考：
	逻辑回归模型能用准确率来评测吗？
答案：
	可以，但是结果不精准，因为逻辑回归模型主要用于二分类，即：A类还是B类，不能说97%的A类，3%的B类。
	所以要通过混淆矩阵来评测，即：精确率，召回率，F1值（F1-Score），ROC曲线，AUC值。


------------------分类问题评估------------------
混淆矩阵、精确率、召回率、F1-score、AUC指标、ROC曲线

		混淆矩阵四个指标
1.真实值是正例的样本中，被分类为 正例的样本数量有多少，叫做真正例（TP，True Positive）
2.真实值是正例的样本中，被分类为 假例 的样本数量有多少，叫做伪反例（FN，False Negative）
3.真实值是假例 的样本中，被分类为 正例 的样本数量有多少,叫做伪正例（FP，False Positive）
4.真实值是假例的样本中，被分类为 假例的样本数量有多少，叫做真反例（TN，True Negative）

5.	精确率：TP/ （TP + FP） = 1./(1. + 3.)
6.	召回率：TP/（TP + FN） = 1./(1. + 2.)

		2*精确率*召回率			2 * 5. * 6.
F1:=	------------------	= ---------------
		精确率+召回率			   5. + 6.


精确率(Precision)
	·查准率，对正例样本的预测准确率。比如：把恶性肿瘤当做正例样本，
		想知道模型对恶性肿瘤的预测准确率。
	·计算方法：P= TP / (TP+FP)


召回率（Recall）－概念
	也叫查全率，指的是预测为真正例样本占所有真实正例样本的比重,例如：
		恶性肿瘤当做正例样本，则我们想知道模型是否能把所有的恶性肿瘤患者都预测出来。
	计算方法：P = TP / (TP+FN)

----------------------ROC曲线、AUC指标----------------------

真正率TPR与假正率FPR
	1正样本中被预测为正样本的概率TPR（TruePositive Rate） 真正率：TP/（TP+FN）Y
	2负样本中被预测为正样本的概率FPR (False Positive Rate)	假正率：FP/（FP+TN）X
	通过这两个指标可以描述模型对正/负样本的分辨能力

ROC曲线 (Receiver Operating Characteristic curve)
	是一种常用于评估分类模型性能的可视化工具。ROC曲线以模型的真正率TPR为纵轴 Y，假正率FPR为横轴 X，它将模型在不同阀值下的表现以曲线的形式展现出来。
	
AUC （Area Under the ROC Curve）曲线下面积
	ROC曲线的优劣可以通过曲线下的面积（AUC）来衡量，AUC越大表示分类器性能越好。
	当AUC=0.5时，表示分类器的性能等同于随机猜测	(.5,.5)
	当AUC=1时，表示分类器的性能完美，能够完全正确地将正负例分类。(0,1)(X,Y)

	------------------------------------
AUC的计算api
	from sklearn.metrics import roc_auc_score
	sklearn. metrics.roc_auc_score(y_true, y_score)
	
	计算ROC曲线面积，即AUC值
	y_true：每个样本的真实类别，必须为0(反例)，1(正例)标记
	y_score：预测得分，可以是正例的估计概率、置信值或者分类器方法的返回值

分类评估报告api
	sklearn. metrics.classification_report(y_true, y_pred, labels=[],target_names=None )
		y_true：真实目标值
		y_pred：估计器预测目标值labels:指定类别对应的数字
		target_names：目标类别名称
		returmn：每个类别精确率与召回率

------------------------------案例 －电信客户流失预测-------------------------
数据集介绍
	CustomerID客户ID
	Gender性别
	partneratt配偶是否也为att用户
	dependents_att家人是否也是att用户
	landline是否使用att固话服务
	internet_att/internet_other是否使用att的互联网服务
	Paymentbank/creditcard/electroinc付款方式
	MonthlyCharges每月话费
	TotalCharges累计话费
	Contract_month/1year用户使用月度/年度合约
	StreamingTv/streamingMovies是否使用在线视频或者电影app
	Churn客户转化的flag		<----标签

案例需求
	已知：用户个人，通话，上网等信息数据
	需求：通过分析特征属性确定用户流失的原因，以及哪些因素可能导致用户流失。建立预测模型来判断用户是否流失，并提出用户流失预警策略。

案例步骤分析
	·1、数据基本处理
		主要是查看数据行/列数量
		对类别数据数据进行one-hot处理
		查看标签分布情况
	2、特征筛选
		分析哪些特征对标签值影响大
		对标签进行分组统计，对比0/1标签分组后的均值等
		初步筛选出对标签影响比较大的特征，形成x、y
	·3、模型训练
		样本均衡情况下模型训练
		样本不平衡情况下模型训练
		交叉验证网格搜素等方式模型训练
	4、模型评估
		精确率
		Roc_AUC指标计算

	one-hot处理: 对列的类别,提取出来,组成-添加新的类别
		热编码:  str		---> bool,  bool  原来的消失...
		bool			bool			str
	Gender Male	Gender Female	 ←	Gender
	Yes					No			 ←	Male


		# 将标准化后的numpy数组转回DataFrame，保持列名
X_dataframe = pd.DataFrame(X_scaled, columns=feature_names)














