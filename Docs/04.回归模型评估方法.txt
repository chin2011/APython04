
=============回归模型评估方法===================
线性回归模型评估－MAE、MSE、RMSE三种指标
	·为什么要进行线性回归模型的评估
		我们希望衡量预测值和真实值之间的差距，
		会用到MAE、MSE、RMSE多种测评函数进行评价

均方误差 Mean Squared Error MSE
	MSE越小模型预测约准确
	from sklearn. metrics import mean_squared_error
	mean_squared_error(y_test, y_predict)

平均绝对误差Mean Absolute Error MAE
	MAE越小模型预测约准确
	from sklearn.metrics import mean_absolute_error
	mean_absolute_error (y_test, y_predict)


均方根误差 Root Mean Squared Error (RMSE)
	RMSE越小模型预测约准确
	RMSE是MSE的平方根，某些情况下比MES更有用

	MAE和RMSE非常接近，都表明模型的误差很低。MAE或RMSE越小，误差越小！
结论：RMSE > MAE都能反应真实误差，但是RMSE会对异常点更加敏感
	使用中:RMSE , MAE 一起用


---------------------------线性回归API和案例---------------
		----------线性回归API、案例波士顿房价预测----------
	LinearRegression
	正规方程 y=wx+b
属性：LinearRegression.coef_（回归系数）	w
		LinearRegression.intercept_（偏置）	b
---
	SGDRegressor 随机梯度下降
参数
	loss（损失函数类型）eg：loss=”squared_loss
	fit_intercept（是否计算偏置）
	learning rate（学习率策略）：string，optional，可以配置学习率随着迭代次数不断减小
		比如：学习率不断变小策略："invscaling' : eta = eta0 / pow(t, power_t=0.25)
	eta0=0.01	（学习率的值）
属性
	SGDRegressor.coef_（回归系数） 
	SGDRegressor.intercept_（偏置）	
	
		------------------波士顿房价----------------
	CRIM	城镇人均犯罪率
	ZN	占地面积超过2.5万平方英尺的住宅用地比例
	INDUS	城镇非零售业务地区的比例
	CHAS	查尔斯河虚拟变量（=1如果土地在河边；否则是0）
	NOX	一氧化氮浓度（每1000万份）
	RM	平均每居民房数
	AGE	在1940年之前建成的所有者占用单位的比例
	DIS	与五个波士顿就业中心的加权距离
	RAD	辐射状公路的可达性指数
	TAX	每10,000美元的全额物业税率
	PTRATIO	城镇师生比例
	B1000（Bk-0.63)^2	其中Bk是城镇的黑人比例
	LSTAT	人口中地位较低人群的百分数
	MEDV	以1000美元计算的自有住房的中位数	
	

--------------------------欠拟合和过拟合---------------------
	出现原因、解决方法、L1正则化、L2正则化

	------------欠拟合------------
模型在训练集上表现不好，在测试集上也表现不好。模型过于简单
欠拟合在训练集和测试集上的误差都较大
	
欠拟合出现的原因
	·学习到数据的特征过少
解决办法【从数据、模型、算法的角度去想解决方案】
	·添加其他特征
		·有时出现欠拟合是因为特征项不够导致的，可以添加其他特征项来解决
		·“组合”、“泛化”、“相关性”三类特征是特征添加的重要手段
	添加多项式特征项
		模型过于简单时的常用套路，例如将线性模型通过添加二次项或三次项使模型泛化能力更强


	------------过拟合------------
模型在训练集上表现好，在测试集上表现不好。模型过于复杂
过拟合在训练集上误差较小，而测试集上误差较大
	
过拟合出现的原因
	原始特征过多，存在一些嘈杂特征，模型过于复杂是因为模型尝试去兼顾各个测试数据点
解决办法
	·重新清洗数据
		·对于过多异常点数据、数据不纯的地方 再处理
	增大数据的训练量
		·对原来的数据训练的太过了，增加数据量的情况下，会缓解
	正则化
		·解决模型过拟合的方法，在机器学习、深度学习中大量使用
	减少特征维度，防止维灾难
		·由于特征多，样本数量少，导致学习不充分，泛化能力差。

	
	
	------------正则化 →解决:过拟合------------
L1正则:	将不重要特征前的参数值为0  ==
	from sklearn.1inear_model import Lasso
L2正则:	将不重要特征前的参数趋近0  ~
	from sklearn. linear_model import Ridge

正则化概念（出现的原因）
	·在模型训练时，数据中有些特征影响模型复杂度、或者某个特征的异常值较多，
		所以要尽量减少这个特征的影响（甚至删除某个特征的影响），这就是正则化。
正则化如何消除异常点带来的w值过大过小的影响？
	·在损失函数中增加正则化项
		·分为L1正则化、L2正则化

L1正则化，在损失函数中添加L1正则化项
	J1 = MSE =+ a* |w..|	
	
	. a叫做惩罚系数，该值越大则权重调整的幅度就越大，即：表示对特征权重惩罚力度就越大
	. L1正则化会使得权重趋向于0，甚至等于0，使得某些特征失效，达到特征筛选的目的

	使用L1 正则化的线性回归模型是 Lasso回归

L2正则化，在损失函数中添加L2正则化项
	J2 = MSE =+ a* |w..|²	
	
	. a叫做惩罚系数，该值越大则权重调整的幅度就越大，即：表示对特征权重惩罚力度就越大
	. L2正则化会使得权重趋向于0，一般不等于0

	使用L2正则化的线性回归模型是 岭回归

对 过拟合模型L1正则化调整
	Lasso回归L1正则, 会将高次方项系数变为0

对 过拟合模型L2正则化调整
	Ridge线性回归12正则不会将系数变为0, 但是对高次方项系数影响较大
	
工程开发中L1、L2使用建议：
	一般倾向使用L2正则。
---------------------

回顾：
	欠拟合：	模型在训练集 和 测试集表现效果都不好.
	正好拟合：	模型在训练集和测试集表现效果都好.
	过拟合：	模型在训练集表现好，测试集表现不好，

过拟合，欠拟合解释：
	产生原因：
		欠拟合：模型简单.
		过拟合：模型复杂.
	解决方案：
		欠拟合：增加特征，从而增加模型的复杂度.
		过拟合：减少模型复杂度，手动筛选（减少）特征，L1和L2正则化.

大白话：
	我要去爬山，带了个小包，装了：登山杖，水，面包，衣服，雨伞，鞋子.·，发现包装不下了。
	L1正则化：可以实现去掉一些不是必选的，例如：当天去，当前回，且天气晴朗→不带雨伞，鞋子，即：权重为0
	L2正则化：换一个非常非常大的包，还是那些物品，但是空间占用（权重）就变小了.·


